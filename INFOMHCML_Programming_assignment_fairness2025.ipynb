{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvGd4YgtppjR"
      },
      "source": [
        "## Submission instructions\n",
        "\n",
        "All code that you write should be in this notebook. Please include your names and student numbers. You have to submit this notebook, with your code and answers filled in. Make sure to add enough documentation.\n",
        "\n",
        "For questions, make use of the \"Lab\" session (see schedule).\n",
        "Questions can also be posted to the MS teams channel called \"Lab\".\n",
        "\n",
        "**Note:** You are free to make use of Python libraries (e.g., numpy, sklearn, etc.) except any *fairness* libraries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0P9dsbAffgfZ"
      },
      "source": [
        "#### Name and student numbers\n",
        "Jep Antonisse 3312070 Elias Hendriks 5930413 \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ni3V-7iqA6X"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "In this assignment we are going to use the **COMPAS** dataset.\n",
        "\n",
        "If you haven't done so already, take a look at this article: https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing.\n",
        "For background on the dataset, see https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm.\n",
        "\n",
        "**Reading in the COMPAS dataset**\n",
        "\n",
        "The dataset can be downloaded here: https://github.com/propublica/compas-analysis/blob/master/compas-scores-two-years.csv\n",
        "\n",
        "For this assignment, we focus on the protected attribute *race*.\n",
        "\n",
        "The label (the variable we want to be able to predict) represents recidivism, which is defined as a new arrest within 2 years."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajLXEdx6plgP",
        "outputId": "a65bf36a-1bc6-488f-accc-7bd9b24ca411"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-05-12 11:38:58--  https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -c https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "AaT9DQwwpqkx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "compas_data = pd.read_csv('compas-scores-two-years.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsidUr4Bz-gZ"
      },
      "source": [
        "We apply several data preprocessing steps, including only retaining Caucasians and African Americans."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "vs2eRxdgrHrt"
      },
      "outputs": [],
      "source": [
        "compas_data = compas_data[(compas_data.days_b_screening_arrest <= 30)\n",
        "            & (compas_data.days_b_screening_arrest >= -30)\n",
        "            & (compas_data.is_recid != -1)\n",
        "            & (compas_data.c_charge_degree != 'O')\n",
        "            & (compas_data.score_text != 'N/A')\n",
        "            & ((compas_data.race == 'Caucasian') | (compas_data.race == 'African-American'))]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5IwB6Rz2zIS"
      },
      "source": [
        "Take a look at the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMM-MYdstObf",
        "outputId": "0bf826a7-bf28-433b-ea6a-b21c5f3f1fe6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    id              name      first    last compas_screening_date     sex  \\\n",
            "1    3       kevon dixon      kevon   dixon            2013-01-27    Male   \n",
            "2    4          ed philo         ed   philo            2013-04-14    Male   \n",
            "6    8     edward riddle     edward  riddle            2014-02-19    Male   \n",
            "8   10  elizabeth thieme  elizabeth  thieme            2014-03-16  Female   \n",
            "10  14    benjamin franc   benjamin   franc            2013-11-26    Male   \n",
            "\n",
            "           dob  age       age_cat              race  ...  v_decile_score  \\\n",
            "1   1982-01-22   34       25 - 45  African-American  ...               1   \n",
            "2   1991-05-14   24  Less than 25  African-American  ...               3   \n",
            "6   1974-07-23   41       25 - 45         Caucasian  ...               2   \n",
            "8   1976-06-03   39       25 - 45         Caucasian  ...               1   \n",
            "10  1988-06-01   27       25 - 45         Caucasian  ...               4   \n",
            "\n",
            "    v_score_text  v_screening_date  in_custody  out_custody  priors_count.1  \\\n",
            "1            Low        2013-01-27  2013-01-26   2013-02-05               0   \n",
            "2            Low        2013-04-14  2013-06-16   2013-06-16               4   \n",
            "6            Low        2014-02-19  2014-03-31   2014-04-18              14   \n",
            "8            Low        2014-03-16  2014-03-15   2014-03-18               0   \n",
            "10           Low        2013-11-26  2013-11-25   2013-11-26               0   \n",
            "\n",
            "   start  end event two_year_recid  \n",
            "1      9  159     1              1  \n",
            "2      0   63     0              1  \n",
            "6      5   40     1              1  \n",
            "8      2  747     0              0  \n",
            "10     0  857     0              0  \n",
            "\n",
            "[5 rows x 53 columns]\n"
          ]
        }
      ],
      "source": [
        "print(compas_data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vKapT6FtmvJ"
      },
      "source": [
        "Now take a look at the distribution of the protected attribute `race` and the distribution of our outcome variable `two_year_recid`.\n",
        "\n",
        "**Note:** in the context of fair machine learning, the favorable label here is no recidivism, i.e., ```two_year_recid = 0```. So think about how what you will code as the positive class in your machine learning experiments, and make sure your interpretation of the results is consistent with this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fh2oM2yptnjR",
        "outputId": "f89ff857-41d9-4a8c-d236-6fd4af65f177"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of instances per race category:\n",
            "race              two_year_recid\n",
            "African-American  1                 1661\n",
            "                  0                 1514\n",
            "Caucasian         0                 1281\n",
            "                  1                  822\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print('Number of instances per race category:')\n",
        "print(compas_data[['race', 'two_year_recid']].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "636Yopp6wNtY"
      },
      "source": [
        "## Data analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hS3g2NT98dY_"
      },
      "source": [
        "### **1. Exploration**\n",
        "\n",
        "First we perform an exploratory analysis of the data.\n",
        "\n",
        "**Question:** What is the size of the data? (i.e. how many data instances does it contain?)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "k6FESAE1VmPu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of data instances:\n",
            "5278\n",
            "Number of features:\n",
            "53\n"
          ]
        }
      ],
      "source": [
        "# Your code\n",
        "print('Number of data instances:')\n",
        "print(compas_data.shape[0])\n",
        "print('Number of features:')\n",
        "print(compas_data.shape[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kx-EDiJ41-_O"
      },
      "source": [
        "**Question:** In the dataset, the protected attribute is `race`, which has two categories: White and African Americans. How many data instances belong to each category?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "e9WqGTz5237Y"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of instances per race category:\n",
            "race            \n",
            "African-American    3175\n",
            "Caucasian           2103\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Your code\n",
        "print('Number of instances per race category:')\n",
        "print(compas_data[['race']].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLdMWSNK3OPt"
      },
      "source": [
        "**Question:** What are the base rates (the probability of a favorable outcome for the two protected attribute classes)?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "3OoqKyud3jIY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Percentage of individuals with no recidivism (two_year_recid == 0):\n",
            "African-American: 47.69%\n",
            "Caucasian: 60.91%\n",
            "----\n",
            "Percentage of individuals with no recidivism (two_year_recid == 0):\n",
            "Female: 63.82%\n",
            "Male: 50.32%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Your code\n",
        "def base_rate(attribute):\n",
        "    grouped_by_a = compas_data.groupby(attribute)['two_year_recid']\n",
        "    total_per_a = grouped_by_a.count()\n",
        "\n",
        "    no_recid = grouped_by_a.apply(lambda x: (x == 0).sum())\n",
        "    percentage_no_recid = (no_recid/total_per_a) * 100\n",
        "\n",
        "    percentages = []\n",
        "    print(\"Percentage of individuals with no recidivism (two_year_recid == 0):\")\n",
        "    for a in percentage_no_recid.index:\n",
        "        print(f\"{a}: {percentage_no_recid[a]:.2f}%\")\n",
        "        percentages.append(percentage_no_recid[a])\n",
        "    return percentages\n",
        "\n",
        "base_rate('race')\n",
        "print(\"----\")\n",
        "base_rate('sex')\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lr-0I7It3pBY"
      },
      "source": [
        "**Question:** What are the base rates for the combination of both race and sex categories?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "3SCmOWs43t9r"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Percentage of individuals with no recidivism (two_year_recid == 0):\n",
            "('African-American', 'Female'): 63.02%\n",
            "('African-American', 'Male'): 44.48%\n",
            "('Caucasian', 'Female'): 64.73%\n",
            "('Caucasian', 'Male'): 59.78%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Your code\n",
        "base_rate(['race', 'sex'])\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2qyyoS74UGC"
      },
      "source": [
        "**Question**\n",
        "\n",
        "Write down a short interpretation of the statistics you calculated. What do you see?\n",
        "> Answer:\n",
        "- Most data instances (around 60%) have an African-American background\n",
        "- The percentage of recedivism is much lower for Caucasian people than African-American People\n",
        "- The percentage of recedivism is much lower for women than men. This holds for both races seperately as well\n",
        "- Only for African-American males is the recedivism percentage more than 50%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-mxqnnUcaGc"
      },
      "source": [
        "### **2. Performance measures**\n",
        "\n",
        "You will have to measure the performance and fairness of different classifiers in question 5. The performance will be calculated with the precision, recall, F1 and accuracy.\n",
        "Additionally, you will have to calculate the statistical/demographic parity, the true positive rate (recall) and false positive rate per race group.\n",
        "\n",
        "Make sure that you are able to calculate these metrics in the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "IAO99gf2caZT"
      },
      "outputs": [],
      "source": [
        "# Your code for the performance measures\n",
        "def performance(model_predictions, true_labels_data):\n",
        "    # predictions have different indices, so we set them anew\n",
        "    model_predictions = model_predictions.reset_index(drop=True)\n",
        "    true_labels_data = true_labels_data.reset_index(drop=True)\n",
        "    \n",
        "    # Since no recidivism is the positive label, we can compute the confusion matrix:\n",
        "    tp = ((model_predictions['pred'] == 0) & (true_labels_data['two_year_recid'] == 0)).sum()\n",
        "    fp = ((model_predictions['pred'] == 0) & (true_labels_data['two_year_recid'] == 1)).sum()\n",
        "\n",
        "    tn = ((model_predictions['pred'] == 1) & (true_labels_data['two_year_recid'] == 1)).sum()\n",
        "    fn = ((model_predictions['pred'] == 1) & (true_labels_data['two_year_recid'] == 0)).sum()\n",
        "\n",
        "    # true positives / all positives\n",
        "    precision = tp / (tp + fp)\n",
        "\n",
        "    # true positives / all labels 0\n",
        "    recall = tp / (tp + fn)\n",
        "\n",
        "    # false positive / all labels 1\n",
        "    fpr = fp / (fp + tn)\n",
        "\n",
        "    # all true predictions / total intences\n",
        "    accuracy = (tp + tn) / (tp + fp + tn + fn)\n",
        "\n",
        "\n",
        "    f1 = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "    print(f\"Accuracy: {100 * accuracy:.2f}%\")\n",
        "    print(f\"Precision: {100 * precision:.2f}%\")\n",
        "    print(f\"Recall: {100 * recall:.2f}%\")\n",
        "    print(f\"False Negative Rate: {100 * fpr:.2f}\")\n",
        "    print(f\"F1-score: {f1:.2f}\")\n",
        "    return [accuracy, precision, recall, f1]\n",
        "\n",
        "def group_performance(model_predictions, data, true_labels_data, attribute):\n",
        "\n",
        "    data['pred'] = model_predictions['pred'].values #add the predictions to the datapoints\n",
        "    data['two_year_recid'] = true_labels_data['two_year_recid'].values #add the true lables to the datapoints\n",
        "\n",
        "    grouped_by_a = data.groupby(attribute)['pred'] #sort on \n",
        "    total_per_a = grouped_by_a.count()\n",
        "\n",
        "    no_recid = grouped_by_a.apply(lambda x: (x == 0).sum())\n",
        "    percentage_no_recid = (no_recid/total_per_a) * 100\n",
        "\n",
        "    print(\"Percentage of individuals in a subgroup with no recidivism predicted:\")\n",
        "    percentages = []\n",
        "    races = ['African-American', 'Caucasian']\n",
        "    for a in percentage_no_recid.index:\n",
        "        print(f\"{races[a]}: {percentage_no_recid[a]:.2f}%\")\n",
        "        percentages.append(percentage_no_recid[a])\n",
        "    print(f\"statistical parity: {percentages[0]/percentages[1]:.2f}\")\n",
        "\n",
        "    black = data[data['race'] == 0]\n",
        "    white = data[data['race'] == 1]\n",
        "\n",
        "    print(\"\\nDivided on sensitive attribute 'race':\")\n",
        "    print(\"\\nAfrican-American:\")\n",
        "    performance(black[['pred']], black[['two_year_recid']])\n",
        "    print(\"\\nCaucasian:\")\n",
        "    performance(white[['pred']], white[['two_year_recid']])\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n51Bdpy59vhy"
      },
      "source": [
        "### **3. Prepare the data**\n",
        "For the classifiers in question 5, the input of the model can only contain numerical values, it is therefore important to convert the strings in the columns (features) of interest of the `compas_data` to floats or integers.\n",
        "\n",
        "The columns of interest are features that you think will be informative or interesting in predicting the outcome variable.\n",
        "Use the cell below to explore which of the Compas variables you need to convert to be able to use them for the classifiers.\n",
        "\n",
        "Generate a new dataframe with your selected features in the right encoding (also make sure to include `two_year_recid`). You can implement this yourself, or use the `LabelEncoder` from `sklearn`.\n",
        "\n",
        "**Note:** you do not need to convert all columns/features, only the ones you are interested in. However, do **not** include the feature `is_recid`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "2G0-QxbH95rX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['id', 'name', 'first', 'last', 'compas_screening_date', 'sex', 'dob',\n",
            "       'age', 'age_cat', 'race', 'juv_fel_count', 'decile_score',\n",
            "       'juv_misd_count', 'juv_other_count', 'priors_count',\n",
            "       'days_b_screening_arrest', 'c_jail_in', 'c_jail_out', 'c_case_number',\n",
            "       'c_offense_date', 'c_arrest_date', 'c_days_from_compas',\n",
            "       'c_charge_degree', 'c_charge_desc', 'is_recid', 'r_case_number',\n",
            "       'r_charge_degree', 'r_days_from_arrest', 'r_offense_date',\n",
            "       'r_charge_desc', 'r_jail_in', 'r_jail_out', 'violent_recid',\n",
            "       'is_violent_recid', 'vr_case_number', 'vr_charge_degree',\n",
            "       'vr_offense_date', 'vr_charge_desc', 'type_of_assessment',\n",
            "       'decile_score.1', 'score_text', 'screening_date',\n",
            "       'v_type_of_assessment', 'v_decile_score', 'v_score_text',\n",
            "       'v_screening_date', 'in_custody', 'out_custody', 'priors_count.1',\n",
            "       'start', 'end', 'event', 'two_year_recid'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>priors_count</th>\n",
              "      <th>c_charge_degree</th>\n",
              "      <th>r_charge_degree</th>\n",
              "      <th>vr_charge_degree</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>two_year_recid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    priors_count  c_charge_degree  r_charge_degree  vr_charge_degree  race  \\\n",
              "1              0                0                3                 2     0   \n",
              "2              4                0                6                 8     0   \n",
              "6             14                0                2                 8     1   \n",
              "8              0                1                9                 8     1   \n",
              "10             0                0                9                 8     1   \n",
              "\n",
              "    sex  two_year_recid  \n",
              "1     1               1  \n",
              "2     1               1  \n",
              "6     1               1  \n",
              "8     0               0  \n",
              "10    1               0  "
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Your code to prepare the data\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "print(compas_data.columns)\n",
        "\n",
        "\n",
        "selected_features_categorical = ['c_charge_degree', 'r_charge_degree', 'vr_charge_degree']\n",
        "selected_features_numerical = ['priors_count']\n",
        "\n",
        "\n",
        "prepared_compas_data = pd.DataFrame()\n",
        "\n",
        "\n",
        "# turn the strings into their exact integer value\n",
        "for feature in selected_features_numerical:\n",
        "    prepared_compas_data[feature] = compas_data[feature].astype(int)\n",
        "\n",
        "# for categorical features, we have to assign them integer values\n",
        "for feature in selected_features_categorical:\n",
        "    le = LabelEncoder()\n",
        "    prepared_compas_data[feature] = le.fit_transform(compas_data[feature])\n",
        "\n",
        "\n",
        "# Protected Features\n",
        "le = LabelEncoder()\n",
        "prepared_compas_data['race'] = le.fit_transform(compas_data['race'])\n",
        "le = LabelEncoder()\n",
        "prepared_compas_data['sex'] = le.fit_transform(compas_data['sex'])\n",
        "\n",
        "\n",
        "prepared_compas_data['two_year_recid'] = compas_data['two_year_recid'].astype(int)\n",
        "\n",
        "le = LabelEncoder()\n",
        "prepared_compas_data['race'] = le.fit_transform(compas_data['race'])\n",
        "le = LabelEncoder()\n",
        "prepared_compas_data['sex'] = le.fit_transform(compas_data['sex'])\n",
        "\n",
        "prepared_compas_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-ILbSsR-ZW_"
      },
      "source": [
        "**Question**\n",
        "\n",
        "Give a short motivation (one-two sentence) per feature why you think this is informative or interesting to take into account.\n",
        "> Answer:\n",
        "* priors count: this is a measure of the number of offenses commited in the past. This can provide important insight if the defendent has learned from previous mistakes. We purposely exclude felonies comitedded as a juvenile, since\n",
        "\n",
        "* current charge degree: this shows the extend of the current crime, on which we should base our verdict. Naturally, more serious crimes can be indicators of a more profound role in the crimal circuit and therefore a higher chance of recidivism.\n",
        "\n",
        "* r/vr charge degree: this gives us some indication if the defendent has already commited crimes on a higher level in the past. Similarly to that of the current charge degree, this can provide insight in the type of crimes commited\n",
        "\n",
        "We purposely excluded:\n",
        "\n",
        "* Personal information, such as age, since we deemed them irrelevant for the court. Law would and should treat all adults similarly, despite e.g. an age difference.\n",
        "* decile score: this is a score of risk of recidivism provided by an algorithms. Although this could be seem as highly relevant, since this is also our objective, we will not utilize it since we want to stay clear of any other artificial computed scores. That way, we make sure that any bias in our classification is not due to hidden biases in the decile score algorithm."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkgRPopIxNVJ"
      },
      "source": [
        "### **4. Train and test split**\n",
        "\n",
        "Divide the dataset into a train (80%) and test split (20%), either by implementing it yourself, or by using an existing library.\n",
        "\n",
        "**Note:** Usually when carrying out machine learning experiments,\n",
        "we also need a dev set for developing and selecting our models (incl. tuning of hyper-parameters).\n",
        "However, in this assignment, the goal is not to optimize\n",
        "the performance of models so we'll only use a train and test split.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "G0wUGEpiV7mH"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>priors_count</th>\n",
              "      <th>c_charge_degree</th>\n",
              "      <th>r_charge_degree</th>\n",
              "      <th>vr_charge_degree</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1956</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2846</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5333</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1546</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4766</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      priors_count  c_charge_degree  r_charge_degree  vr_charge_degree  race  \\\n",
              "1956             3                1                6                 5     1   \n",
              "2846             5                1                6                 8     1   \n",
              "5333             1                0                3                 8     0   \n",
              "1546             2                1                9                 8     1   \n",
              "4766             0                1                9                 8     1   \n",
              "\n",
              "      sex  \n",
              "1956    1  \n",
              "2846    1  \n",
              "5333    1  \n",
              "1546    1  \n",
              "4766    0  "
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Your code to split the data\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    prepared_compas_data[selected_features_numerical + selected_features_categorical + ['race', 'sex']], prepared_compas_data['two_year_recid'], test_size=0.2  # 20% test, 80% train\n",
        ")\n",
        "\n",
        "x_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kmq45GgAWEJo"
      },
      "source": [
        "### **5. Classifiers**\n",
        "\n",
        "Now, train and test different classifiers and report the following statistics:\n",
        "\n",
        "* Overall performance:\n",
        "\n",
        "  * Precision\n",
        "  * Recall\n",
        "  * F1\n",
        "  * Accuracy\n",
        "\n",
        "* Fairness performance:\n",
        "\n",
        "  * The statistical parity difference for the protected attribute `race`(i.e. the difference in the probability of receiving a favorable label between the two protected attribute groups);\n",
        "  * The true positive rates of the two protected attribute groups\n",
        "  * The false positive rates of the two protected attribute groups.\n",
        "\n",
        "For training the classifier we recommend using scikit-learn (https://scikit-learn.org/stable/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zu6eQ_3xGfXd"
      },
      "source": [
        "#### **5.1 Regular classification**\n",
        "Train a logistic regression classifier with the race feature and all other features that you are interested in."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 96.21%\n",
            "Precision: 98.51%\n",
            "Recall: 94.29%\n",
            "False Negative Rate: 1.61\n",
            "F1-score: 0.96\n",
            "Percentage of individuals in a subgroup with no recidivism predicted:\n",
            "African-American: 45.62%\n",
            "Caucasian: 57.95%\n",
            "statistical parity: 0.79\n",
            "\n",
            "Divided on sensitive attribute 'race':\n",
            "\n",
            "African-American:\n",
            "Accuracy: 95.94%\n",
            "Precision: 98.58%\n",
            "Recall: 92.95%\n",
            "False Negative Rate: 1.26\n",
            "F1-score: 0.96\n",
            "\n",
            "Caucasian:\n",
            "Accuracy: 96.59%\n",
            "Precision: 98.43%\n",
            "Recall: 95.80%\n",
            "False Negative Rate: 2.25\n",
            "F1-score: 0.97\n"
          ]
        }
      ],
      "source": [
        "# Your code for classifier 1\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model_with_race = LogisticRegression()\n",
        "model_with_race.fit(x_train[selected_features_numerical + selected_features_categorical + ['race']], y_train)\n",
        "\n",
        "predictions = pd.DataFrame(model_with_race.predict(x_test[selected_features_numerical + selected_features_categorical + ['race']]), columns=['pred'])\n",
        "true_labels = pd.DataFrame(y_test, columns=['two_year_recid'])\n",
        "\n",
        "perf = performance(predictions, true_labels)\n",
        "group_performance(predictions, x_test, true_labels, 'race')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### **5.2 Without the protected attribute**\n",
        "Train a logistic regression classifier without the race feature, but with all other features you used in 5.1.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "WL7LSSMPFmhv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 96.21%\n",
            "Precision: 98.51%\n",
            "Recall: 94.29%\n",
            "False Negative Rate: 1.61\n",
            "F1-score: 0.96\n",
            "Percentage of individuals in a subgroup with no recidivism predicted:\n",
            "African-American: 45.62%\n",
            "Caucasian: 57.95%\n",
            "statistical parity: 0.79\n",
            "\n",
            "Divided on sensitive attribute 'race':\n",
            "\n",
            "African-American:\n",
            "Accuracy: 95.94%\n",
            "Precision: 98.58%\n",
            "Recall: 92.95%\n",
            "False Negative Rate: 1.26\n",
            "F1-score: 0.96\n",
            "\n",
            "Caucasian:\n",
            "Accuracy: 96.59%\n",
            "Precision: 98.43%\n",
            "Recall: 95.80%\n",
            "False Negative Rate: 2.25\n",
            "F1-score: 0.97\n"
          ]
        }
      ],
      "source": [
        "# Your code for classifier 2\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "model_without_race = LogisticRegression()\n",
        "model_without_race.fit(x_train[selected_features_categorical + selected_features_numerical], y_train)\n",
        "\n",
        "wr_predictions = pd.DataFrame(model_without_race.predict(x_test[selected_features_categorical + selected_features_numerical]), columns=['pred'])\n",
        "wr_true_labels = pd.DataFrame(y_test, columns=['two_year_recid'])\n",
        "\n",
        "wr_perf = performance(wr_predictions, wr_true_labels)\n",
        "group_performance(wr_predictions, x_test, wr_true_labels, 'race')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5H_mlbM6qij9"
      },
      "source": [
        "**Question**\n",
        "\n",
        "Write down a short interpretation of the results you calculated. What do you see?\n",
        "> Answer:\n",
        "\n",
        "We see that we are able to train a pretty good classifier, with quite high accuracy, precision and recall. Therefore, the percentage of individuals predicted a zero is quite close to the base rate for both race values. However, this also means that chances of being assigned a zero is not equal for both races: we can see a statistical parity of 0.4495/0.6102 = 0.74 (with the train-test-split at the time of writing). Considering a common treshold of 0.8, this means the classifier does not satisfy the fairness criterion of equal decision measures.\n",
        "\n",
        "We can see this inequallity when we devide the data on the sensitive attribute race. Since a high percentage of the African-Americans has a label of 1, our classifier shows some more difficulties in assigning them the label 0 compared to the Caucasian population. This is most noticeable in the recall: there is quite a differnce in the ability to assign all non-recidivism individuals a 0 between the two ethnicity groups, with African-Americans being more often wrongly assinged a 1.\n",
        "\n",
        "We would expect that removing the sensitive attribute column from the data would results in a decrease in this inequality of decision measures. After all, if the model is unable to see from which group an individual is from, it should prohibit decision making on race and force decsions on crimes alone. Therefore, individuals with similar crimes yet diffent races should be treated identical, therefore lowering the bias in the data and the statical parity.\n",
        "\n",
        "However, against our expectations, both models return identical predictions on the test data set. This means that peformance for the model with the sensitive attribute is the same as for the model that excludes race. Altough suprising, we believe it might highlight the fact that fairness is not achieved through unawareness: leaving out the race attribute is not a solution if its value is strongly correlated with the other features we use. If this is the case, these proxies can allow the model to still predict the race group without being able to see that specific column. Considering the models performance, we think that the crime data might be able to reflect the race data, e.g. because African-American individuals commit on average more serious crimes, making the column about the race itself redundant for optimal classification.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwiX0vEXFlgU"
      },
      "source": [
        "#### **5.3 Pre-processing: Reweighing**\n",
        "Train and test a classifier with weights (see lecture slide for the weight calculation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-1Vw1_xk4aQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "If race and label are independent, we would expect to observe the probabilies:\n",
            "African-American, 0: 0.3186\n",
            "African-American, 1: 0.2830\n",
            "Caucasian, 0: 0.2110\n",
            "Caucasian, 1: 0.1874\n",
            "\n",
            "Therefore, we need to reweigh into:\n",
            "African-American, 0: 1.1105\n",
            "African-American, 1: 0.8993\n",
            "Caucasian, 0: 0.8694\n",
            "Caucasian, 1: 1.2036\n",
            "\n",
            "Accuracy: 97.63%\n",
            "Precision: 99.25%\n",
            "Recall: 96.17%\n",
            "F1-score: 0.98\n",
            "Percentage of individuals in a subgroup with no recidivism predicted:\n",
            "African-American: 45.66%\n",
            "Caucasian: 57.14%\n",
            "statistical parity: 0.80\n",
            "\n",
            "Divided on sensitive attribute 'race':\n",
            "\n",
            "African-American:\n",
            "Accuracy: 97.24%\n",
            "Precision: 99.60%\n",
            "Recall: 95.74%\n",
            "F1-score: 0.98\n",
            "\n",
            "Caucasian:\n",
            "Accuracy: 97.91%\n",
            "Precision: 98.94%\n",
            "Recall: 96.56%\n",
            "F1-score: 0.98\n"
          ]
        }
      ],
      "source": [
        "# Your code for classifier 3\n",
        "def base_rate_reweigh(attribute):\n",
        "    # Group sizes probability:\n",
        "    group_size = compas_data[[attribute]].value_counts()\n",
        "    group_prob = group_size/len(compas_data)\n",
        "\n",
        "    # Label probability\n",
        "    label_size = compas_data[['two_year_recid']].value_counts()\n",
        "    label_prob = label_size/len(compas_data)\n",
        "\n",
        "    print(f\"If {attribute} and label are independent, we would expect to observe the probabilies:\")\n",
        "    for a in group_prob.index:\n",
        "        for l in label_prob.index:\n",
        "            print(f\"{a[0]}, {l[0]}: {group_prob[a] * label_prob[l]:.4f}\")\n",
        "\n",
        "    #print(\"\\nHowever we observe:\")\n",
        "    observed_probability = compas_data[['race', 'two_year_recid']].value_counts() / len(compas_data)\n",
        "    #print(observed_probability)\n",
        "\n",
        "    print(\"\\nTherefore, we need to reweigh into:\")\n",
        "    for a in group_prob.index:\n",
        "        for l in label_prob.index:\n",
        "            print(f\"{a[0]}, {l[0]}: {((group_prob[a] * label_prob[l]) / observed_probability[a[0], l[0]]):.4f}\")\n",
        "    return\n",
        "\n",
        "\n",
        "base_rate_reweigh('race')\n",
        "\n",
        "print()\n",
        "\n",
        "weights = []\n",
        "\n",
        "for index, point in x_train.iterrows():\n",
        "    race = point['race']\n",
        "    recid = y_train.loc[index]\n",
        "    \n",
        "    if race == 0 and recid == 0:\n",
        "        weights.append(1.1105)\n",
        "    elif race == 0 and recid == 1:\n",
        "        weights.append(0.8993)\n",
        "    elif race == 1 and recid == 0:\n",
        "        weights.append(0.8694)\n",
        "    elif race == 1 and recid == 1:\n",
        "        weights.append(1.2036)\n",
        "\n",
        "weighted_model_without_race = LogisticRegression()\n",
        "weighted_model_without_race.fit(x_train[selected_features_categorical + selected_features_numerical], y_train,\n",
        "sample_weight=weights)\n",
        "\n",
        "rw_predictions = pd.DataFrame(weighted_model_without_race.predict(x_test[selected_features_categorical + selected_features_numerical]), columns=['pred'])\n",
        "rw_true_labels = pd.DataFrame(y_test, columns=['two_year_recid'])\n",
        "\n",
        "\n",
        "rw_perf = performance(rw_predictions, rw_true_labels)\n",
        "group_performance(rw_predictions, x_test, rw_true_labels, 'race')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yHv79yvv00a"
      },
      "source": [
        "**Question**\n",
        "\n",
        " Report the 4 weights that are used for reweighing and a short **interpretation/discussion** of the weights and the classifier results.\n",
        "> Answer:\n",
        "The weights for combinations of race and outcome are:\n",
        "\n",
        "African-American, 0: 1.1105,\n",
        "\n",
        "African-American, 1: 0.8993,\n",
        "\n",
        "Caucasian, 0: 0.8694,\n",
        "\n",
        "Caucasian, 1: 1.2036,\n",
        "\n",
        "This shows that African-American in combination with 0 and Caucasian in combination with 1 have smaller probabilities than expected with an independent relation between attribute and outcome. Therefore, we increase the weight of the underreperesented classes and decrease those that are overrepresented in the classifier, such that the joint distribution resembles the expected distribution more closely.\n",
        "\n",
        "We would expect that increasing the sample weights would result in more equal classification between the race groups. This is, because with this more balanced distribution, the large difference in base rates (percentage of non-recidivism) should be leveled out for both groups. However, quite suprisingly, the model with these weights was unable to increase its performance. We believe this could be because the difference and not that large, resulting in weights quite close to 1. Therefore, it might be the case that this reweighing is not able to have the profound effect that can chance the decisions of the classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3XdW0qF82JC"
      },
      "source": [
        "#### **5.4 Post-processing: Equalized odds**\n",
        "Use the predictions by the first classifier for this post processing part (see lecture slides for more information about post processing for equalized odds).\n",
        "\n",
        "We have the following parameters (A indicates group membership, Y_{hat} the original prediction, Y_{tilde} the prediction of the derived predictor).\n",
        "\n",
        "* `p_00` = P(Y_{tilde} = 1 | Y_{hat} = 0 & A = 0)\n",
        "* `p_01` = P(Y_{tilde} = 1 | Y_{hat} = 0 & A = 1)\n",
        "* `p_10` = P(Y_{tilde} = 1 | Y_{hat} = 1 & A = 0)\n",
        "* `p_11` = P(Y_{tilde} = 1 | Y_{hat} = 1 & A = 1)\n",
        "\n",
        "\n",
        "Normally, the best parameters `p_00, p_01, p_10, p_11` are found with a linear program that minimizes loss between predictions of a derived predictor and the actual labels. In this assignment we will not ask you to do this. Instead, we would like you to follow the next steps to find parameters, post-process the data and check the performance of this classifier with post-processing:\n",
        "\n",
        "1. Generate 5000 different samples of these 4 parameters randomly;\n",
        "2. Write a function (or more) that applies these 4 parameters to postprocess the predictions.\n",
        "3. For each generated set of 4 parameters:\n",
        "  - Change the predicted labels with the function(s) from step 2;\n",
        "  - Evaluate these 'new' predictions, by calculating group-wise TPR and FPR, as well as overall performance based on F1 and/or accuracy.\n",
        "4. Choose the best set of parameters. Take into account the equalized odds fairness measure, as well a performance measure like accuracy or F1.\n",
        "5. Check the overall performance (precision, recall, accuracy, F1, etc.) of the new predictions after post-processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "Nk_scQdM76He"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{(0, 0): 0.854737764342836, (0, 1): 0.6601852897361286, (1, 0): 0.6693255084887851, (1, 1): 0.9580250740412501}\n"
          ]
        }
      ],
      "source": [
        "# Your code for step 1\n",
        "import random\n",
        "\n",
        "random_parameters = []\n",
        "for _ in range(5000):\n",
        "  p_00 = random.uniform(0,1)\n",
        "  p_01 = random.uniform(0,1)\n",
        "  p_10 = random.uniform(0,1)\n",
        "  p_11 = random.uniform(0,1)\n",
        "  random_parameters.append({(0, 0): p_00,\n",
        "                            (0, 1): p_01,\n",
        "                            (1, 0): p_10,\n",
        "                            (1, 1): p_11})\n",
        "\n",
        "# Example, first set of random parameters\n",
        "print(random_parameters[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "W0p92txObr6v"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Your code for step 2\n",
        "# Create a dataframe with the necessary information\n",
        "compas_data = compas_data[compas_data['race'].isin(['African-American', 'Caucasian'])].copy()\n",
        "compas_data['race_num'] = compas_data['race'].map({'Caucasian': 0, 'African-American': 1})\n",
        "\n",
        "pred_labels_df = predictions.values.ravel()\n",
        "true_labels_df = true_labels.values.ravel()\n",
        "compas_subset = compas_data.loc[x_test.index].copy()\n",
        "\n",
        "df_post_data = pd.DataFrame({'race_num': compas_subset['race_num'].values, #Deze krijg ik niet de goede size\n",
        "                             'pred_labels': pred_labels_df,\n",
        "                             'true_labels': true_labels_df})\n",
        "\n",
        "# the number of cases falling in each condition\n",
        "subset_sizes = {\n",
        "    (0, 0): len(df_post_data.query('pred_labels == 0 & race_num == 0')),\n",
        "    (0, 1): len(df_post_data.query('pred_labels == 0 & race_num == 1')),\n",
        "    (1, 0): len(df_post_data.query('pred_labels == 1 & race_num == 0')),\n",
        "    (1, 1): len(df_post_data.query('pred_labels == 1 & race_num == 1'))\n",
        "}\n",
        "\n",
        "def generate_labels(subset_sizes, p_dict):\n",
        "    new_predictions = {}\n",
        "\n",
        "    for (prediction, group), p in p_dict.items():\n",
        "\n",
        "      # The number of instances for which we need to generate labels\n",
        "      num_instances = subset_sizes[(prediction, group)]\n",
        "\n",
        "      # Write your code here.\n",
        "      new_labels = np.random.binomial(n=1, p=p, size=num_instances)\n",
        "      # save the new predictions\n",
        "      new_predictions[(prediction, group)] = new_labels\n",
        "\n",
        "    return new_predictions\n",
        "  \n",
        "def post_processing(df, new_predictions):\n",
        "    df = df.copy()\n",
        "    df['postprocessed_preds'] = np.nan\n",
        "\n",
        "    for (pred_val, group_val), labels in new_predictions.items():\n",
        "        mask = (df['pred_labels'] == pred_val) & (df['race_num'] == group_val)\n",
        "        df.loc[mask, 'postprocessed_preds'] = labels\n",
        "\n",
        "    df['postprocessed_preds'] = df['postprocessed_preds'].astype(int)\n",
        "    return df\n",
        "\n",
        "# Compute TPR/FPR per group and overall metrics\n",
        "def compute_group_metrics(df, pred_col='postprocessed_preds'):\n",
        "    group_stats = {}\n",
        "    for group in [0, 1]:\n",
        "        sub = df[df['race_num'] == group]\n",
        "        y_true = sub['true_labels']\n",
        "        y_pred = sub[pred_col]\n",
        "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()\n",
        "        tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
        "        group_stats[group] = {'TPR': tpr, 'FPR': fpr}\n",
        "    return group_stats\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "teZWyupiw2iM"
      },
      "outputs": [],
      "source": [
        "# Step 3\n",
        "best_result = {\n",
        "    'score': -np.inf,\n",
        "    'params': None,\n",
        "    'df': None,\n",
        "    'group_metrics': None\n",
        "}\n",
        "\n",
        "for p_set in random_parameters:\n",
        "    new_preds = generate_labels(subset_sizes, p_set)\n",
        "    df_eval = post_processing(df_post_data, new_preds)\n",
        "    group_metrics = compute_group_metrics(df_eval)\n",
        "\n",
        "    # Calculate TPR gap and F1\n",
        "    tpr_gap = abs(group_metrics[0]['TPR'] - group_metrics[1]['TPR'])\n",
        "\n",
        "    y_true = df_eval['true_labels'].values\n",
        "    y_pred = df_eval['postprocessed_preds'].values\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()\n",
        "\n",
        "    precision = tp / (tp + fp)\n",
        "    recall = tp / (tp + fn)\n",
        "    accuracy = (tp + tn) / (tp + fp + tn + fn)\n",
        "    f1 = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "    score = f1 - tpr_gap\n",
        "\n",
        "    if score > best_result['score']:\n",
        "        best_result.update({\n",
        "            'score': score,\n",
        "            'params': p_set,\n",
        "            'df': df_eval,\n",
        "            'group_metrics': group_metrics,\n",
        "            'confusion_matrix': (tn, fp, fn, tp)\n",
        "        })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "q-t-ZljWBBS9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameters:\n",
            "  P(Ỹ=1 | Ŷ=0, A=0) = 0.053\n",
            "  P(Ỹ=1 | Ŷ=0, A=1) = 0.059\n",
            "  P(Ỹ=1 | Ŷ=1, A=0) = 0.986\n",
            "  P(Ỹ=1 | Ŷ=1, A=1) = 0.967\n",
            "\n",
            "Group-wise TPR/FPR:\n",
            "  Group 0: TPR = 0.966, FPR = 0.084\n",
            "  Group 1: TPR = 0.965, FPR = 0.134\n",
            "\n",
            "Overall performance:\n",
            "Accuracy: 92.52%\n",
            "Precision: 88.54%\n",
            "Recall: 96.57%\n",
            "F1-score: 0.92\n"
          ]
        }
      ],
      "source": [
        "# Your code for step 4 and 5\n",
        "# Step 4\n",
        "print(\"Best parameters:\")\n",
        "for (yhat, group), prob in best_result['params'].items():\n",
        "    print(f\"  P(Ỹ=1 | Ŷ={yhat}, A={group}) = {prob:.3f}\")\n",
        "\n",
        "print(\"\\nGroup-wise TPR/FPR:\")\n",
        "for g, stats in best_result['group_metrics'].items():\n",
        "    print(f\"  Group {g}: TPR = {stats['TPR']:.3f}, FPR = {stats['FPR']:.3f}\")\n",
        "\n",
        "# Step 5\n",
        "tn, fp, fn, tp = best_result['confusion_matrix']\n",
        "\n",
        "precision = tp / (tp + fp) if (tp + fp) else 0\n",
        "recall = tp / (tp + fn) if (tp + fn) else 0\n",
        "accuracy = (tp + tn) / (tp + fp + tn + fn) if (tp + fp + tn + fn) else 0\n",
        "f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) else 0\n",
        "\n",
        "print(\"\\nOverall performance:\")\n",
        "print(f\"Accuracy: {100 * accuracy:.2f}%\")\n",
        "print(f\"Precision: {100 * precision:.2f}%\")\n",
        "print(f\"Recall: {100 * recall:.2f}%\")\n",
        "print(f\"F1-score: {f1:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DD0weMlkN4Cq"
      },
      "source": [
        "**Question**\n",
        "\n",
        "Describe how you selected the best set of parameters. Furthermore, how do you interpret the best set of parameters that you found? And what do you think of the results of the new classifier?\n",
        ">Answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwtRtf1Pl5_u"
      },
      "source": [
        "#### **Overall discussion**\n",
        "For all 4 classifiers that you trained, describe:\n",
        "- Does this classifier satisfies statistical parity?\n",
        "- Does the classifier satisfy the equal opportunity criterion?\n",
        "\n",
        "Finally, how do the different classifiers compare against each other?\n",
        "\n",
        ">Answer\n",
        "\n",
        "* The first three classifiers have identical results:\n",
        "- Seeing if they satisfy statistical parity is easy, since we calculated that as a group performance measure. Using the common treshold of 0.8, our classifiers fall just below that bar. Therefore, we say that different race groups are not equally likely to be assigned the label 0 in our classifiers\n",
        "- To see if the equal opportunity criterion holds for these models, we need to examine the true positive rate/recall measure between the groups. For all three classifiers, we do see a difference in favor of the Caucausian rate in terms of recall. This means the models have slight inequallities in treating people with similar outcome the same. However, since we should keep in mind that these differences are quite small, around one percent.\n",
        "\n",
        "* The forth classifier has different performance measure:\n",
        "- For the equal opportunity criterion, we see that the TPR between both groups is (almost) identical. This shows that the model does satisfy the equal opportunity criterion.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUPZN32kOJ9H"
      },
      "source": [
        "### **6. Intersectional fairness**\n",
        "In the questions above `race` was the only protected attribute. However, multiple protected attributes sometimes interact, leading to different fairness outcomes for different combinations of these protected attributes.\n",
        "\n",
        "Now explore the intersectional fairness for protected attributes `race` and `sex` for the first two classifiers from question 5. Make a combination of the `race` and `sex` column, resulting in four new subgroups (e.g., female Caucasian), and report the maximum difference between the subgroups for statistical parity, TPR and FPR.\n",
        "For example, suppose we have four groups with TPRs 0.1, 0.2, 0.3, 0.8, then the maximum difference is 0.7."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-siRd0cUH0sN"
      },
      "source": [
        "Your code to evaluate intersectional fairness for Classifier 1:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "mSXG9sBjT-xX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Intersectional statistical parity with no recidivism predicted\n",
            "1_Male: 0.416\n",
            "0_Male: 0.553\n",
            "1_Female: 0.654\n",
            "0_Female: 0.667\n",
            "1_Male: 0.989\n",
            "0_Male: 0.986\n",
            "1_Female: 0.971\n",
            "0_Female: 0.941\n",
            "1_Male: 0.079\n",
            "0_Male: 0.046\n",
            "1_Female: 0.043\n",
            "0_Female: 0.029\n",
            "\n",
            "Max disparity:\n",
            "Statistical Parity gap: 0.25065104166666663\n",
            "TPR gap: 0.04826014913007459\n",
            "FPR gap: 0.049535603715170275\n"
          ]
        }
      ],
      "source": [
        "# Your code for intersectional fairness\n",
        "compas_subset = compas_data.loc[x_test.index].copy()\n",
        "df_post_data['sex'] = compas_subset['sex'].values\n",
        "\n",
        "df_post_data['intersectional'] = df_post_data['race_num'].astype(str) + \"_\" + df_post_data['sex'].astype(str)\n",
        "\n",
        "parity_intersect = {}\n",
        "TPR_intersect = {}\n",
        "FPR_intersect = {}\n",
        "\n",
        "for combo in df_post_data['intersectional'].unique():\n",
        "    sectional = df_post_data[df_post_data['intersectional'] == combo]\n",
        "    parity_intersect[combo] = (sectional['pred_labels'] == 0).mean()\n",
        "    \n",
        "    y_true = sectional['true_labels']\n",
        "    y_pred = sectional['pred_labels']\n",
        "    \n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0, 1]).ravel()\n",
        "    TPR_intersect[combo] = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    FPR_intersect[combo] = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
        "    \n",
        "print(\"Intersectional statistical parity with no recidivism predicted\")\n",
        "for group, value in parity_intersect.items():\n",
        "    print(f\"{group}: {value:.3f}\")\n",
        "for group, value in TPR_intersect.items():\n",
        "    print(f\"{group}: {value:.3f}\")\n",
        "for group, value in FPR_intersect.items():\n",
        "    print(f\"{group}: {value:.3f}\")\n",
        "    \n",
        "print()\n",
        "print(\"Max disparity:\")\n",
        "print(f\"Statistical Parity gap: {max(parity_intersect.values()) - min(parity_intersect.values())}\")\n",
        "print(f\"TPR gap: {max(TPR_intersect.values()) - min(TPR_intersect.values())}\")\n",
        "print(f\"FPR gap: {max(FPR_intersect.values()) - min(FPR_intersect.values())}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oz_hNpkGH1ul"
      },
      "source": [
        "Your code to evaluate intersectional fairness for Classifier 2:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "MwvWChS2H79s"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Intersectional statistical parity with no recidivism predicted\n",
            "1_Male: 0.667\n",
            "0_Male: 0.667\n",
            "1_Female: 0.667\n",
            "0_Female: 0.667\n",
            "1_Male: 0.989\n",
            "0_Male: 0.986\n",
            "1_Female: 0.971\n",
            "0_Female: 0.941\n",
            "1_Male: 0.079\n",
            "0_Male: 0.046\n",
            "1_Female: 0.043\n",
            "0_Female: 0.029\n",
            "\n",
            "Max disparity:\n",
            "Statistical Parity gap: 0.0\n",
            "TPR gap: 0.04826014913007459\n",
            "FPR gap: 0.049535603715170275\n"
          ]
        }
      ],
      "source": [
        "# Your code for intersectional fairness Classifier 2\n",
        "\n",
        "pred_labels_2 = wr_predictions.values.ravel()\n",
        "true_labels_2 = wr_true_labels.values.ravel()\n",
        "compas_subset_2 = compas_data.loc[x_test.index].copy()\n",
        "\n",
        "df_post_data_2 = pd.DataFrame({'race_num': compas_subset_2['race_num'].values,\n",
        "                             'pred_labels': pred_labels_2,\n",
        "                             'true_labels': true_labels_2})\n",
        "compas_subset_2 = compas_data.loc[x_test.index].copy()\n",
        "df_post_data_2['sex'] = compas_subset_2['sex'].values\n",
        "\n",
        "df_post_data_2['intersectional'] = df_post_data_2['race_num'].astype(str) + \"_\" + df_post_data_2['sex'].astype(str)\n",
        "\n",
        "parity_intersect_2 = {}\n",
        "TPR_intersect_2 = {}\n",
        "FPR_intersect_2 = {}\n",
        "\n",
        "for combo in df_post_data_2['intersectional'].unique():\n",
        "    sectional_2 = df_post_data_2[df_post_data_2['intersectional'] == combo]\n",
        "    parity_intersect_2[combo] = (sectional['pred_labels'] == 0).mean()\n",
        "    \n",
        "    y_true_2 = sectional_2['true_labels']\n",
        "    y_pred_2 = sectional_2['pred_labels']\n",
        "    \n",
        "    tn, fp, fn, tp = confusion_matrix(y_true_2, y_pred_2, labels=[0, 1]).ravel()\n",
        "    TPR_intersect_2[combo] = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    FPR_intersect_2[combo] = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
        "    \n",
        "print(\"Intersectional statistical parity with no recidivism predicted\")\n",
        "for group, value in parity_intersect_2.items():\n",
        "    print(f\"{group}: {value:.3f}\")\n",
        "for group, value in TPR_intersect_2.items():\n",
        "    print(f\"{group}: {value:.3f}\")\n",
        "for group, value in FPR_intersect_2.items():\n",
        "    print(f\"{group}: {value:.3f}\")\n",
        "    \n",
        "print()\n",
        "print(\"Max disparity:\")\n",
        "print(f\"Statistical Parity gap: {max(parity_intersect_2.values()) - min(parity_intersect_2.values())}\")\n",
        "print(f\"TPR gap: {max(TPR_intersect_2.values()) - min(TPR_intersect_2.values())}\")\n",
        "print(f\"FPR gap: {max(FPR_intersect_2.values()) - min(FPR_intersect_2.values())}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyE6wo8EH-E0"
      },
      "source": [
        "**Question**\n",
        "\n",
        "Write down a short interpretation of the results you calculated. What do you see?\n",
        "> Answer:\n",
        "\n",
        "- The TPR and FPR gap is extremely small, showing that TPR and FPR values for all subgroups lie very close together. Therefore, it performs well on the equal opportunity criterion, since people with similar outcomes are thus assigned similar labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lfFYnU1V_bl"
      },
      "source": [
        "## Discussion\n",
        "Provide a short ethical discussion (1 or 2 paragraphs) reflecting on these two aspects:\n",
        "\n",
        "1) The use of a ML system to try to predict recidivism;\n",
        "\n",
        "2) The public release of a dataset like this.\n",
        "\n",
        "> Answer\n",
        "\n",
        "The use of artificial decision making systems, especially in these high consequence fields such as the justice system, is an emerging trend accompanied with legitimate concerns about fairness. As we can see from our experiment, historical data can be biased, which limits the classifier's ability to make correct decisions for underrepresented subgroups. Furthermore, we saw that removing these biases, by excluding sensitive information or including sample weights, does not always has the profound increase in equality one might hope. Altough one might argue that accuracy can be valued above fairness, having a more WYSIWYG approach, we should never overlook the effect the models decisions have on human lives. Discriminatory models can maintain and even amplify exisiting historical biases, by directing human action in based stereotypical believes.\n",
        "\n",
        "The release of datasets like COMPAS to the public is a good step towards more transparency in these classification tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
