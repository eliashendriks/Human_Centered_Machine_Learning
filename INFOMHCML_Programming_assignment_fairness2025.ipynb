{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvGd4YgtppjR"
      },
      "source": [
        "## Submission instructions\n",
        "\n",
        "All code that you write should be in this notebook. Please include your names and student numbers. You have to submit this notebook, with your code and answers filled in. Make sure to add enough documentation.\n",
        "\n",
        "For questions, make use of the \"Lab\" session (see schedule).\n",
        "Questions can also be posted to the MS teams channel called \"Lab\".\n",
        "\n",
        "**Note:** You are free to make use of Python libraries (e.g., numpy, sklearn, etc.) except any *fairness* libraries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0P9dsbAffgfZ"
      },
      "source": [
        "#### Name and student numbers\n",
        "Jep Antonisse 3312070 Elias Hendriks 5930413 \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ni3V-7iqA6X"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "In this assignment we are going to use the **COMPAS** dataset.\n",
        "\n",
        "If you haven't done so already, take a look at this article: https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing.\n",
        "For background on the dataset, see https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm.\n",
        "\n",
        "**Reading in the COMPAS dataset**\n",
        "\n",
        "The dataset can be downloaded here: https://github.com/propublica/compas-analysis/blob/master/compas-scores-two-years.csv\n",
        "\n",
        "For this assignment, we focus on the protected attribute *race*.\n",
        "\n",
        "The label (the variable we want to be able to predict) represents recidivism, which is defined as a new arrest within 2 years."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajLXEdx6plgP",
        "outputId": "a65bf36a-1bc6-488f-accc-7bd9b24ca411"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'wget' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!wget -c https://raw.githubusercontent.com/propublica/compas-analysis/master/compas-scores-two-years.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AaT9DQwwpqkx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "compas_data = pd.read_csv('compas-scores-two-years.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsidUr4Bz-gZ"
      },
      "source": [
        "We apply several data preprocessing steps, including only retaining Caucasians and African Americans."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vs2eRxdgrHrt"
      },
      "outputs": [],
      "source": [
        "compas_data = compas_data[(compas_data.days_b_screening_arrest <= 30)\n",
        "            & (compas_data.days_b_screening_arrest >= -30)\n",
        "            & (compas_data.is_recid != -1)\n",
        "            & (compas_data.c_charge_degree != 'O')\n",
        "            & (compas_data.score_text != 'N/A')\n",
        "            & ((compas_data.race == 'Caucasian') | (compas_data.race == 'African-American'))]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5IwB6Rz2zIS"
      },
      "source": [
        "Take a look at the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMM-MYdstObf",
        "outputId": "0bf826a7-bf28-433b-ea6a-b21c5f3f1fe6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    id              name      first    last compas_screening_date     sex  \\\n",
            "1    3       kevon dixon      kevon   dixon            2013-01-27    Male   \n",
            "2    4          ed philo         ed   philo            2013-04-14    Male   \n",
            "6    8     edward riddle     edward  riddle            2014-02-19    Male   \n",
            "8   10  elizabeth thieme  elizabeth  thieme            2014-03-16  Female   \n",
            "10  14    benjamin franc   benjamin   franc            2013-11-26    Male   \n",
            "\n",
            "           dob  age       age_cat              race  ...  v_decile_score  \\\n",
            "1   1982-01-22   34       25 - 45  African-American  ...               1   \n",
            "2   1991-05-14   24  Less than 25  African-American  ...               3   \n",
            "6   1974-07-23   41       25 - 45         Caucasian  ...               2   \n",
            "8   1976-06-03   39       25 - 45         Caucasian  ...               1   \n",
            "10  1988-06-01   27       25 - 45         Caucasian  ...               4   \n",
            "\n",
            "    v_score_text  v_screening_date  in_custody  out_custody  priors_count.1  \\\n",
            "1            Low        2013-01-27  2013-01-26   2013-02-05               0   \n",
            "2            Low        2013-04-14  2013-06-16   2013-06-16               4   \n",
            "6            Low        2014-02-19  2014-03-31   2014-04-18              14   \n",
            "8            Low        2014-03-16  2014-03-15   2014-03-18               0   \n",
            "10           Low        2013-11-26  2013-11-25   2013-11-26               0   \n",
            "\n",
            "   start  end event two_year_recid  \n",
            "1      9  159     1              1  \n",
            "2      0   63     0              1  \n",
            "6      5   40     1              1  \n",
            "8      2  747     0              0  \n",
            "10     0  857     0              0  \n",
            "\n",
            "[5 rows x 53 columns]\n"
          ]
        }
      ],
      "source": [
        "print(compas_data.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vKapT6FtmvJ"
      },
      "source": [
        "Now take a look at the distribution of the protected attribute `race` and the distribution of our outcome variable `two_year_recid`.\n",
        "\n",
        "**Note:** in the context of fair machine learning, the favorable label here is no recidivism, i.e., ```two_year_recid = 0```. So think about how what you will code as the positive class in your machine learning experiments, and make sure your interpretation of the results is consistent with this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fh2oM2yptnjR",
        "outputId": "f89ff857-41d9-4a8c-d236-6fd4af65f177"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of instances per race category:\n",
            "race              two_year_recid\n",
            "African-American  1                 1661\n",
            "                  0                 1514\n",
            "Caucasian         0                 1281\n",
            "                  1                  822\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print('Number of instances per race category:')\n",
        "print(compas_data[['race', 'two_year_recid']].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "636Yopp6wNtY"
      },
      "source": [
        "## Data analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hS3g2NT98dY_"
      },
      "source": [
        "### **1. Exploration**\n",
        "\n",
        "First we perform an exploratory analysis of the data.\n",
        "\n",
        "**Question:** What is the size of the data? (i.e. how many data instances does it contain?)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "k6FESAE1VmPu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of data instances:\n",
            "5278\n"
          ]
        }
      ],
      "source": [
        "# Your code\n",
        "print('Number of data instances:')\n",
        "print(compas_data.shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kx-EDiJ41-_O"
      },
      "source": [
        "**Question:** In the dataset, the protected attribute is `race`, which has two categories: White and African Americans. How many data instances belong to each category?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "e9WqGTz5237Y"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of instances per race category:\n",
            "race            \n",
            "African-American    3175\n",
            "Caucasian           2103\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Your code\n",
        "print('Number of instances per race category:')\n",
        "print(compas_data[['race']].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLdMWSNK3OPt"
      },
      "source": [
        "**Question:** What are the base rates (the probability of a favorable outcome for the two protected attribute classes)?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "3OoqKyud3jIY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Percentage of individuals with no recidivism (two_year_recid == 0):\n",
            "African-American: 47.69%\n",
            "Caucasian: 60.91%\n",
            "----\n",
            "Percentage of individuals with no recidivism (two_year_recid == 0):\n",
            "Female: 63.82%\n",
            "Male: 50.32%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Your code\n",
        "def base_rate(attribute):\n",
        "    grouped_by_a = compas_data.groupby(attribute)['two_year_recid']\n",
        "    total_per_a = grouped_by_a.count()\n",
        "\n",
        "    no_recid = grouped_by_a.apply(lambda x: (x == 0).sum())\n",
        "    percentage_no_recid = (no_recid/total_per_a) * 100\n",
        "\n",
        "    percentages = []\n",
        "    print(\"Percentage of individuals with no recidivism (two_year_recid == 0):\")\n",
        "    for a in percentage_no_recid.index:\n",
        "        print(f\"{a}: {percentage_no_recid[a]:.2f}%\")\n",
        "        percentages.append(percentage_no_recid[a])\n",
        "    return percentages\n",
        "\n",
        "base_rate('race')\n",
        "print(\"----\")\n",
        "base_rate('sex')\n",
        "print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lr-0I7It3pBY"
      },
      "source": [
        "**Question:** What are the base rates for the combination of both race and sex categories?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "3SCmOWs43t9r"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Percentage of individuals with no recidivism (two_year_recid == 0):\n",
            "('African-American', 'Female'): 63.02%\n",
            "('African-American', 'Male'): 44.48%\n",
            "('Caucasian', 'Female'): 64.73%\n",
            "('Caucasian', 'Male'): 59.78%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Your code\n",
        "base_rate(['race', 'sex'])\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2qyyoS74UGC"
      },
      "source": [
        "**Question**\n",
        "\n",
        "Write down a short interpretation of the statistics you calculated. What do you see?\n",
        "> Answer:\n",
        "- More black people are in jail\n",
        "- White people have a lower percentage of recedivism.\n",
        "- For both black and white people men have a lower percentage of recedivism."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-mxqnnUcaGc"
      },
      "source": [
        "### **2. Performance measures**\n",
        "\n",
        "You will have to measure the performance and fairness of different classifiers in question 5. The performance will be calculated with the precision, recall, F1 and accuracy.\n",
        "Additionally, you will have to calculate the statistical/demographic parity, the true positive rate (recall) and false positive rate per race group.\n",
        "\n",
        "Make sure that you are able to calculate these metrics in the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "IAO99gf2caZT"
      },
      "outputs": [],
      "source": [
        "# Your code for the performance measures\n",
        "# Your code for the performance measures\n",
        "def performance(predictions, true_labels):\n",
        "    # predictions have different indices, so we set them anew\n",
        "    predictions = predictions.reset_index(drop=True)\n",
        "    true_labels = true_labels.reset_index(drop=True)\n",
        "    \n",
        "    # Since no recidivism is the positive label, we can compute the confusion matrix:\n",
        "    tp = ((predictions['pred'] == 0) & (true_labels['two_year_recid'] == 0)).sum()\n",
        "    fp = ((predictions['pred'] == 0) & (true_labels['two_year_recid'] == 1)).sum()\n",
        "\n",
        "    tn = ((predictions['pred'] == 1) & (true_labels['two_year_recid'] == 1)).sum()\n",
        "    fn = ((predictions['pred'] == 1) & (true_labels['two_year_recid'] == 0)).sum()\n",
        "\n",
        "    # true positives / all positives\n",
        "    precision = tp / (tp + fp)\n",
        "\n",
        "    # true positives / all labels 0\n",
        "    recall = tp / (tp + fn)\n",
        "\n",
        "    # all true predictions / total intences\n",
        "    accuracy = (tp + tn) / (tp + fp + tn + fn)\n",
        "\n",
        "    f1 = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "    print(f\"Accuracy: {100 * accuracy:.2f}%\")\n",
        "    print(f\"Precision: {100 * precision:.2f}%\")\n",
        "    print(f\"Recall: {100 * recall:.2f}%\")\n",
        "    print(f\"F1-score: {f1:.2f}\")\n",
        "    return [accuracy, precision, recall, f1]\n",
        "\n",
        "def group_performance(predictions, data, true_labels, attribute):\n",
        "\n",
        "    data['pred'] = predictions['pred'].values #add the predictions to the datapoints\n",
        "    data['two_year_recid'] = true_labels['two_year_recid'].values #add the true lables to the datapoints\n",
        "\n",
        "    grouped_by_a = data.groupby(attribute)['pred'] #sort on \n",
        "    total_per_a = grouped_by_a.count()\n",
        "\n",
        "    no_recid = grouped_by_a.apply(lambda x: (x == 0).sum())\n",
        "    percentage_no_recid = (no_recid/total_per_a) * 100\n",
        "\n",
        "    print(\"Percentage of individuals in a subgroup with no recidivism predicted:\")\n",
        "    percentages = []\n",
        "    races = ['African-American', 'Caucasian']\n",
        "    for a in percentage_no_recid.index:\n",
        "        print(f\"{races[a]}: {percentage_no_recid[a]:.2f}%\")\n",
        "        percentages.append(percentage_no_recid[a])\n",
        "    print(f\"statistical parity: {percentages[0]/percentages[1]:.2f}\")\n",
        "\n",
        "    black = data[data['race'] == 0]\n",
        "    white = data[data['race'] == 1]\n",
        "\n",
        "    print(\"\\nDivided on sensitive attribute 'race':\")\n",
        "    print(\"\\nAfrican-American:\")\n",
        "    performance(white[['pred']], white[['two_year_recid']])\n",
        "    print(\"\\nCaucasian:\")\n",
        "    performance(black[['pred']], black[['two_year_recid']])\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n51Bdpy59vhy"
      },
      "source": [
        "### **3. Prepare the data**\n",
        "For the classifiers in question 5, the input of the model can only contain numerical values, it is therefore important to convert the strings in the columns (features) of interest of the `compas_data` to floats or integers.\n",
        "\n",
        "The columns of interest are features that you think will be informative or interesting in predicting the outcome variable.\n",
        "Use the cell below to explore which of the Compas variables you need to convert to be able to use them for the classifiers.\n",
        "\n",
        "Generate a new dataframe with your selected features in the right encoding (also make sure to include `two_year_recid`). You can implement this yourself, or use the `LabelEncoder` from `sklearn`.\n",
        "\n",
        "**Note:** you do not need to convert all columns/features, only the ones you are interested in. However, do **not** include the feature `is_recid`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "2G0-QxbH95rX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['id', 'name', 'first', 'last', 'compas_screening_date', 'sex', 'dob',\n",
            "       'age', 'age_cat', 'race', 'juv_fel_count', 'decile_score',\n",
            "       'juv_misd_count', 'juv_other_count', 'priors_count',\n",
            "       'days_b_screening_arrest', 'c_jail_in', 'c_jail_out', 'c_case_number',\n",
            "       'c_offense_date', 'c_arrest_date', 'c_days_from_compas',\n",
            "       'c_charge_degree', 'c_charge_desc', 'is_recid', 'r_case_number',\n",
            "       'r_charge_degree', 'r_days_from_arrest', 'r_offense_date',\n",
            "       'r_charge_desc', 'r_jail_in', 'r_jail_out', 'violent_recid',\n",
            "       'is_violent_recid', 'vr_case_number', 'vr_charge_degree',\n",
            "       'vr_offense_date', 'vr_charge_desc', 'type_of_assessment',\n",
            "       'decile_score.1', 'score_text', 'screening_date',\n",
            "       'v_type_of_assessment', 'v_decile_score', 'v_score_text',\n",
            "       'v_screening_date', 'in_custody', 'out_custody', 'priors_count.1',\n",
            "       'start', 'end', 'event', 'two_year_recid'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>decile_score</th>\n",
              "      <th>priors_count</th>\n",
              "      <th>age_cat</th>\n",
              "      <th>c_charge_degree</th>\n",
              "      <th>r_charge_degree</th>\n",
              "      <th>vr_charge_degree</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>two_year_recid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    decile_score  priors_count  age_cat  c_charge_degree  r_charge_degree  \\\n",
              "1              3             0        0                0                3   \n",
              "2              4             4        2                0                6   \n",
              "6              6            14        0                0                2   \n",
              "8              1             0        0                1                9   \n",
              "10             4             0        0                0                9   \n",
              "\n",
              "    vr_charge_degree  race  sex  two_year_recid  \n",
              "1                  2     0    1               1  \n",
              "2                  8     0    1               1  \n",
              "6                  8     1    1               1  \n",
              "8                  8     1    0               0  \n",
              "10                 8     1    1               0  "
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Your code to prepare the data\n",
        "# Your code to prepare the data\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "print(compas_data.columns)\n",
        "\n",
        "\n",
        "selected_features_categorical = ['age_cat', 'c_charge_degree', 'r_charge_degree', 'vr_charge_degree']\n",
        "selected_features_numerical = ['decile_score', 'priors_count']\n",
        "\n",
        "\n",
        "prepared_compas_data = pd.DataFrame()\n",
        "\n",
        "\n",
        "# turn the strings into their exact integer value\n",
        "for feature in selected_features_numerical:\n",
        "    prepared_compas_data[feature] = compas_data[feature].astype(int)\n",
        "\n",
        "# for categorical features, we have to assign them integer values\n",
        "for feature in selected_features_categorical:\n",
        "    le = LabelEncoder()\n",
        "    prepared_compas_data[feature] = le.fit_transform(compas_data[feature])\n",
        "\n",
        "\n",
        "# Protected Features\n",
        "le = LabelEncoder()\n",
        "prepared_compas_data['race'] = le.fit_transform(compas_data['race'])\n",
        "le = LabelEncoder()\n",
        "prepared_compas_data['sex'] = le.fit_transform(compas_data['sex'])\n",
        "\n",
        "\n",
        "prepared_compas_data['two_year_recid'] = compas_data['two_year_recid'].astype(int)\n",
        "\n",
        "le = LabelEncoder()\n",
        "prepared_compas_data['race'] = le.fit_transform(compas_data['race'])\n",
        "le = LabelEncoder()\n",
        "prepared_compas_data['sex'] = le.fit_transform(compas_data['sex'])\n",
        "\n",
        "prepared_compas_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-ILbSsR-ZW_"
      },
      "source": [
        "**Question**\n",
        "\n",
        "Give a short motivation (one-two sentence) per feature why you think this is informative or interesting to take into account.\n",
        "> Answer:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkgRPopIxNVJ"
      },
      "source": [
        "### **4. Train and test split**\n",
        "\n",
        "Divide the dataset into a train (80%) and test split (20%), either by implementing it yourself, or by using an existing library.\n",
        "\n",
        "**Note:** Usually when carrying out machine learning experiments,\n",
        "we also need a dev set for developing and selecting our models (incl. tuning of hyper-parameters).\n",
        "However, in this assignment, the goal is not to optimize\n",
        "the performance of models so we'll only use a train and test split.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0wUGEpiV7mH"
      },
      "outputs": [],
      "source": [
        "# Your code to split the data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kmq45GgAWEJo"
      },
      "source": [
        "### **5. Classifiers**\n",
        "\n",
        "Now, train and test different classifiers and report the following statistics:\n",
        "\n",
        "* Overall performance:\n",
        "\n",
        "  * Precision\n",
        "  * Recall\n",
        "  * F1\n",
        "  * Accuracy\n",
        "\n",
        "* Fairness performance:\n",
        "\n",
        "  * The statistical parity difference for the protected attribute `race`(i.e. the difference in the probability of receiving a favorable label between the two protected attribute groups);\n",
        "  * The true positive rates of the two protected attribute groups\n",
        "  * The false positive rates of the two protected attribute groups.\n",
        "\n",
        "For training the classifier we recommend using scikit-learn (https://scikit-learn.org/stable/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zu6eQ_3xGfXd"
      },
      "source": [
        "#### **5.1 Regular classification**\n",
        "Train a logistic regression classifier with the race feature and all other features that you are interested in."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDaGo07EWElK"
      },
      "outputs": [],
      "source": [
        "# Your code for classifier 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iM23AP8nFisw"
      },
      "source": [
        "#### **5.2 Without the protected attribute**\n",
        "Train a logistic regression classifier without the race feature, but with all other features you used in 5.1.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WL7LSSMPFmhv"
      },
      "outputs": [],
      "source": [
        "# Your code for classifier 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5H_mlbM6qij9"
      },
      "source": [
        "**Question**\n",
        "\n",
        "Write down a short interpretation of the results you calculated. What do you see?\n",
        "> Answer:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwiX0vEXFlgU"
      },
      "source": [
        "#### **5.3 Pre-processing: Reweighing**\n",
        "Train and test a classifier with weights (see lecture slide for the weight calculation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-1Vw1_xk4aQ"
      },
      "outputs": [],
      "source": [
        "# Your code for classifier 3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yHv79yvv00a"
      },
      "source": [
        "**Question**\n",
        "\n",
        " Report the 4 weights that are used for reweighing and a short **interpretation/discussion** of the weights and the classifier results.\n",
        "> Answer:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3XdW0qF82JC"
      },
      "source": [
        "#### **5.4 Post-processing: Equalized odds**\n",
        "Use the predictions by the first classifier for this post processing part (see lecture slides for more information about post processing for equalized odds).\n",
        "\n",
        "We have the following parameters (A indicates group membership, Y_{hat} the original prediction, Y_{tilde} the prediction of the derived predictor).\n",
        "\n",
        "* `p_00` = P(Y_{tilde} = 1 | Y_{hat} = 0 & A = 0)\n",
        "* `p_01` = P(Y_{tilde} = 1 | Y_{hat} = 0 & A = 1)\n",
        "* `p_10` = P(Y_{tilde} = 1 | Y_{hat} = 1 & A = 0)\n",
        "* `p_11` = P(Y_{tilde} = 1 | Y_{hat} = 1 & A = 1)\n",
        "\n",
        "\n",
        "Normally, the best parameters `p_00, p_01, p_10, p_11` are found with a linear program that minimizes loss between predictions of a derived predictor and the actual labels. In this assignment we will not ask you to do this. Instead, we would like you to follow the next steps to find parameters, post-process the data and check the performance of this classifier with post-processing:\n",
        "\n",
        "1. Generate 5000 different samples of these 4 parameters randomly;\n",
        "2. Write a function (or more) that applies these 4 parameters to postprocess the predictions.\n",
        "3. For each generated set of 4 parameters:\n",
        "  - Change the predicted labels with the function(s) from step 2;\n",
        "  - Evaluate these 'new' predictions, by calculating group-wise TPR and FPR, as well as overall performance based on F1 and/or accuracy.\n",
        "4. Choose the best set of parameters. Take into account the equalized odds fairness measure, as well a performance measure like accuracy or F1.\n",
        "5. Check the overall performance (precision, recall, accuracy, F1, etc.) of the new predictions after post-processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nk_scQdM76He"
      },
      "outputs": [],
      "source": [
        "# Your code for step 1\n",
        "import random\n",
        "\n",
        "random_parameters = []\n",
        "for _ in range(1000):\n",
        "  p_00 = ...\n",
        "  p_01 = ...\n",
        "  p_10 = ...\n",
        "  p_11 = ...\n",
        "  random_parameters.append({(0, 0): p_00,\n",
        "                            (0, 1): p_01,\n",
        "                            (1, 0): p_10,\n",
        "                            (1, 1): p_11})\n",
        "\n",
        "# Example, first set of random parameters\n",
        "print(random_parameters[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0p92txObr6v"
      },
      "outputs": [],
      "source": [
        "# Your code for step 2\n",
        "# Create a dataframe with the necessary information\n",
        "df_post_data = pd.DataFrame({'race_num': ...,\n",
        "                             'pred_labels': ...,\n",
        "                             'true_labels': ...})\n",
        "\n",
        "# the number of cases falling in each condition\n",
        "subset_sizes = {\n",
        "    (0, 0): len(df_post_data.query('pred_labels == 0 & race_num == 0')),\n",
        "    (0, 1): len(df_post_data.query('pred_labels == 0 & race_num == 1')),\n",
        "    (1, 0): len(df_post_data.query('pred_labels == 1 & race_num == 0')),\n",
        "    (1, 1): len(df_post_data.query('pred_labels == 1 & race_num == 1'))\n",
        "\n",
        "}\n",
        "\n",
        "def generate_labels(subset_sizes, p_dict):\n",
        "    \"\"\"\n",
        "    subset_sizes: dict with number of cases falling in each condition\n",
        "    p_dict: the postprocessing parameters\n",
        "    \"\"\"\n",
        "    new_predictions = {}\n",
        "\n",
        "    for (prediction, group), p in p_dict.items():\n",
        "\n",
        "      # The number of instances for which we need to generate labels\n",
        "      num_instances = subset_sizes[(prediction, group)]\n",
        "\n",
        "      # Write your code here.\n",
        "\n",
        "      # save the new predictions\n",
        "      new_predictions[(prediction, group)] = ...\n",
        "\n",
        "    return new_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "teZWyupiw2iM"
      },
      "outputs": [],
      "source": [
        "# Your code for step 3\n",
        "\n",
        "for p_dict in random_parameters:\n",
        "\n",
        "  new_predictions = generate_labels(subset_sizes, p_dict)\n",
        "\n",
        "  # replace the predictions\n",
        "  df_copy = df_post_data.copy()\n",
        "\n",
        "  for (pred, group), p in p_dict.items():\n",
        "\n",
        "    new_preds = new_predictions[(pred,group)]\n",
        "    df_copy.loc[(df_post_data['pred_labels'] == pred) &\n",
        "                (df_post_data['race_num'] == group), 'pred_labels'] = new_preds\n",
        "\n",
        "\n",
        "  # evaluate the new predictions and save the scores\n",
        "  # Write your code here.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-t-ZljWBBS9"
      },
      "outputs": [],
      "source": [
        "# Your code for step 4 and 5\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DD0weMlkN4Cq"
      },
      "source": [
        "**Question**\n",
        "\n",
        "Describe how you selected the best set of parameters. Furthermore, how do you interpret the best set of parameters that you found? And what do you think of the results of the new classifier?\n",
        ">Answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwtRtf1Pl5_u"
      },
      "source": [
        "#### **Overall discussion**\n",
        "For all 4 classifiers that you trained, describe:\n",
        "- Does this classifier satisfies statistical parity?\n",
        "- Does the classifier satisfy the equal opportunity criterion?\n",
        "\n",
        "Finally, how do the different classifiers compare against each other?\n",
        "\n",
        ">Answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUPZN32kOJ9H"
      },
      "source": [
        "### **6. Intersectional fairness**\n",
        "In the questions above `race` was the only protected attribute. However, multiple protected attributes sometimes interact, leading to different fairness outcomes for different combinations of these protected attributes.\n",
        "\n",
        "Now explore the intersectional fairness for protected attributes `race` and `sex` for the first two classifiers from question 5. Make a combination of the `race` and `sex` column, resulting in four new subgroups (e.g., female Caucasian), and report the maximum difference between the subgroups for statistical parity, TPR and FPR.\n",
        "For example, suppose we have four groups with TPRs 0.1, 0.2, 0.3, 0.8, then the maximum difference is 0.7."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-siRd0cUH0sN"
      },
      "source": [
        "Your code to evaluate intersectional fairness for Classifier 1:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mSXG9sBjT-xX"
      },
      "outputs": [],
      "source": [
        "# Your code for intersectional fairness"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oz_hNpkGH1ul"
      },
      "source": [
        "Your code to evaluate intersectional fairness for Classifier 2:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MwvWChS2H79s"
      },
      "outputs": [],
      "source": [
        "# Your code for intersectional fairness"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pyE6wo8EH-E0"
      },
      "source": [
        "**Question**\n",
        "\n",
        "Write down a short interpretation of the results you calculated. What do you see?\n",
        "> Answer:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lfFYnU1V_bl"
      },
      "source": [
        "## Discussion\n",
        "Provide a short ethical discussion (1 or 2 paragraphs) reflecting on these two aspects:\n",
        "\n",
        "1) The use of a ML system to try to predict recidivism;\n",
        "\n",
        "2) The public release of a dataset like this.\n",
        "\n",
        "> Answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xEjSKr56xiZO"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
